name: 'L04'

input: 'coef' input_dim: 1 input_dim: 64 input_dim: 20 input_dim: 20
input: 'label' input_dim: 1 input_dim: 1 input_dim: 160 input_dim: 160
input: 'jpg' input_dim: 1 input_dim: 1 input_dim: 160 input_dim: 160

layer { name: 'DeConv-00' type: 'Deconvolution'
        bottom: 'coef' top: 'DeConv-00'
        param { lr_mult: 1 decay_mult: 1 }
        param { lr_mult: 1 decay_mult: 0 }
        convolution_param { num_output: 1 kernel_size: 8 stride: 8 pad: 0
                            weight_filler { type: 'xavier' }
                            bias_filler { type: 'constant' value: 0 }
        }
}

layer { name: 'CONV_1' type: 'Convolution'
        bottom: 'DeConv-00' top: 'CONV_1'
        param { lr_mult: 1}
        param { lr_mult: 0}
        convolution_param { num_output: 48 kernel_size: 11 stride: 1 pad: 0
                            weight_filler { type: 'xavier' }
                            bias_filler { type: 'constant' value: 0 }
        }
}

layer { name: 'relu1' type: 'ReLU'
        bottom: 'CONV_1' top: 'CONV_1'
}

layer { name: 'CONV_2' type: 'Convolution'
        bottom: 'CONV_1' top: 'CONV_2'
        param { lr_mult: 1 }
        param { lr_mult: 0 }
        convolution_param { num_output: 64 kernel_size: 3 stride: 1 pad: 0
                            weight_filler { type: 'xavier' }
                            bias_filler { type: 'constant'  value: 0 }
        }
}

layer { name: 'relu2' type: 'ReLU'
        bottom: 'CONV_2' top: 'CONV_2'
}

layer { name: 'CONV_3' type: 'Convolution'
        bottom: 'CONV_2' top: 'CONV_3'
        param { lr_mult: 1 }
        param { lr_mult: 0 }
        convolution_param { num_output: 64 kernel_size: 3 stride: 1 pad: 0
                            weight_filler { type: 'xavier' }
                            bias_filler { type: 'constant' value: 0 }
        }
}

layer { name: 'relu2' type: 'ReLU'
        bottom: 'CONV_3' top: 'CONV_3'
}

layer { name: 'CONV_4' type: 'Convolution'
        bottom: 'CONV_3' top: 'CONV_4'
        param { lr_mult: 0.1 }
        param { lr_mult: 0 }
        convolution_param { num_output: 1 kernel_size: 5 stride: 1 pad: 0
                            weight_filler { type: 'gaussian' std: 0.001 }
                            bias_filler { type: 'constant' value: 0 }
        }
}

# Tohle je asi blby napad, data tecou mezi cpu a gpu jak diva...
layer { type: 'Python' name: 'ADD'
        top: 'reconstruction' bottom: 'CONV_4' bottom: 'jpg'    
        python_param { module: 'cnn_image_processing' layer: 'PyAddL' }
}

layer { type: 'Python' name: 'LOSS'
        top: 'loss' bottom: 'reconstruction' bottom: 'jpg' bottom: 'label'
        python_param { module: 'cnn_image_processing' layer: 'PyEuclideanLossLayer'
                       param_str: "pixel_norm: True, psnr_max: 1.02, print: True, print_iter: 10, vis: True, vis_scale: 2, vis_mean: 128, vis_normalize: 0.004"
        }
        loss_weight: 1
}

#layer { type: 'Python' name: 'PSNR'
#        bottom: 'reconstruction' bottom: 'jpg' bottom: 'label'
#	python:param { module: 'cnn_image_processing' layer: 'PyPSNRL'
#                       param_str: 'max: 255'}
#}
